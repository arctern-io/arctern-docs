

<!DOCTYPE html>
<html class="writer-html5" lang="python" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>模拟 Spark Standalone 集群的安装部署 &mdash; Arctern 0.3.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> Arctern
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature_description.html">Feature Description</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cluster/cluster.html">Transform from standalone version to distributed version</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../restful/restful.html">RESTful Service</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Arctern</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>模拟 Spark Standalone 集群的安装部署</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/feature_description/spatiotemporal_analysis/cluster_installation.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spark-standalone">
<h1>模拟 Spark Standalone 集群的安装部署<a class="headerlink" href="#spark-standalone" title="Permalink to this headline">¶</a></h1>
<p>本文介绍使用 Docker 技术在一台主机上启动三个容器，并将它们组织成一个 Spark Standalone 集群。之后，你将在该集群上运行 CPU 版本的 Arctern。三个容器的信息如下：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Host name</th>
<th align="left">IP address</th>
<th align="left">Container name</th>
<th align="left">Type</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">node20</td>
<td align="left">172.18.0.20</td>
<td align="left">node20</td>
<td align="left">master</td>
</tr>
<tr>
<td align="left">node21</td>
<td align="left">172.18.0.21</td>
<td align="left">node21</td>
<td align="left">worker</td>
</tr>
<tr>
<td align="left">node22</td>
<td align="left">172.18.0.22</td>
<td align="left">node22</td>
<td align="left">worker</td>
</tr>
</tbody>
</table><div class="section" id="docker">
<h2>创建 Docker 子网<a class="headerlink" href="#docker" title="Permalink to this headline">¶</a></h2>
<p>创建一个名为<code class="docutils literal notranslate"><span class="pre">arcternet</span></code> 的 Docker 子网：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker network create --subnet<span class="o">=</span><span class="m">172</span>.18.0.0/16 arcternet
</pre></div>
</div>
</div>
<div class="section" id="id1">
<h2>创建集群的共享目录<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>创建一个名为<code class="docutils literal notranslate"><span class="pre">arcternas</span></code>的目录作为集群的共享目录：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir <span class="nv">$HOME</span>/arcternas
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>启动容器<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>启动容器，并设置目录 <strong>$HOME/arcternas</strong> 映射到容器内的 <strong>/arcternas</strong>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run -d -ti --name node20 --hostname node20 --net arcternet --ip <span class="m">172</span>.18.0.20 --add-host node21:172.18.0.21 --add-host node22:172.18.0.22 -v <span class="nv">$HOME</span>/arcternas:/arcternas ubuntu:16.04 bash
docker run -d -ti --name node21 --hostname node21 --net arcternet --ip <span class="m">172</span>.18.0.21 --add-host node20:172.18.0.20 --add-host node22:172.18.0.22 -v <span class="nv">$HOME</span>/arcternas:/arcternas ubuntu:16.04 bash
docker run -d -ti --name node22 --hostname node22 --net arcternet --ip <span class="m">172</span>.18.0.22 --add-host node20:172.18.0.20 --add-host node21:172.18.0.21 -v <span class="nv">$HOME</span>/arcternas:/arcternas ubuntu:16.04 bash
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h2>安装库<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>下面以 <code class="docutils literal notranslate"><span class="pre">node20</span></code> 为例展示如何安装库。你需要对 <code class="docutils literal notranslate"><span class="pre">node21</span></code> 和 <code class="docutils literal notranslate"><span class="pre">node22</span></code> 重复下方所述的操作。</p>
<div class="section" id="id4">
<h3>进入 Docker 节点<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 登录 node20，后续你需要对 node21 和 node22 重复此操作</span>
docker <span class="nb">exec</span> -it node20 bash
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>安装依赖库<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>apt update
apt install -y libgl-dev libosmesa6-dev libglu1-mesa-dev wget openjdk-8-jre openssh-server vim
service ssh start

<span class="c1"># 新建 arcterner 用户</span>
useradd -m arcterner -s /bin/bash

<span class="c1"># 修改 arcterner 用户密码为 arcterner</span>
<span class="nb">echo</span> -e <span class="s2">&quot;arcterner\narcterner&quot;</span> <span class="p">|</span> passwd arcterner

<span class="c1"># 修改目录 /arcternas 为 arcterner 所有</span>
chown -R arcterner:arcterner /arcternas
<span class="nb">exit</span>
</pre></div>
</div>
</div>
<div class="section" id="conda">
<h3>安装 Conda<a class="headerlink" href="#conda" title="Permalink to this headline">¶</a></h3>
<p>以<code class="docutils literal notranslate"><span class="pre">arcterner</span></code>用户登录 Docker 节点：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 以 arcterner 用户登录 node20，后续你需要对 node21 和 node22 重复此操作</span>
docker <span class="nb">exec</span> -it -u arcterner node20 bash
</pre></div>
</div>
<p>在 Docker 节点上安装 Conda：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh
bash ~/miniconda.sh -b
<span class="nb">echo</span> <span class="s2">&quot;source </span><span class="nv">$HOME</span><span class="s2">/miniconda3/etc/profile.d/conda.sh&quot;</span> &gt;&gt; .bashrc
rm ~/miniconda.sh
<span class="nb">exit</span>
</pre></div>
</div>
<p>以<code class="docutils literal notranslate"><span class="pre">arcterner</span></code>用户重新登录 Docker 节点：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 以 arcterner 用户登录 node20，后续你需要对 node21 和 node22 重复此操作</span>
docker <span class="nb">exec</span> -it -u arcterner node20 bash
</pre></div>
</div>
<p>执行 <code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">env</span> <span class="pre">list</span></code> 查询 Conda 环境。如果打印了 <code class="docutils literal notranslate"><span class="pre">base</span></code> 环境，则 Conda 安装生效。</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>hadoop@node20:/$ conda env list

<span class="c1"># conda environments:</span>
base                  *  /home/hadoop/miniconda3
</pre></div>
</div>
</div>
<div class="section" id="arctern">
<h3>安装 Arctern<a class="headerlink" href="#arctern" title="Permalink to this headline">¶</a></h3>
<p>创建一个名为 <code class="docutils literal notranslate"><span class="pre">arctern_env</span></code> 的 Conda 环境，并安装 Arctern：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda create -y -n arctern_env -c conda-forge -c arctern arctern
</pre></div>
</div>
<p>进入 <code class="docutils literal notranslate"><span class="pre">arctern_env</span></code> 环境，并启动 Python：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda activate arctern_env
python
</pre></div>
</div>
<p>尝试打印 <code class="docutils literal notranslate"><span class="pre">arctern_pyspark</span></code> 的版本，检查 Arctern 安装是否成功：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">arctern_pyspark</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">arctern_pyspark</span><span class="o">.</span><span class="n">version</span><span class="p">())</span>
<span class="go">version : 0.2.0</span>
</pre></div>
</div>
</div>
<div class="section" id="spark">
<h3>安装 Spark<a class="headerlink" href="#spark" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 进入 Home 目录</span>
<span class="nb">cd</span> ~/

<span class="c1"># 下载 Spark</span>
wget https://downloads.apache.org/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz

<span class="c1"># 解压 Spark</span>
tar -xvf spark-3.0.0-preview2-bin-hadoop2.7.tgz
rm -rf spark-3.0.0-preview2-bin-hadoop2.7.tgz
</pre></div>
</div>
<p>执行 <code class="docutils literal notranslate"><span class="pre">vim</span> <span class="pre">~/.bashrc</span></code> 以编辑 <strong>bashrc</strong> 文件。 在该文件中添加以下内容:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">SPARK_HOME</span><span class="o">=</span><span class="nv">$HOME</span>/spark-3.0.0-preview2-bin-hadoop2.7
</pre></div>
</div>
<p>执行 <code class="docutils literal notranslate"><span class="pre">vim</span> <span class="pre">～/spark-3.0.0-preview2-bin-hadoop2.7/conf/spark-env.sh</span></code> 以编辑 <strong>spark-env.sh</strong> 文件。文件内容如下:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#! /usr/bin/env bash</span>
<span class="nb">export</span> <span class="nv">PYSPARK_PYTHON</span><span class="o">=</span><span class="nv">$HOME</span>/miniconda3/envs/arctern_env/bin/python
<span class="nv">SPARK_WORKER_CORES</span><span class="o">=</span><span class="m">2</span>
<span class="nv">SPARK_WORKER_MEMORY</span><span class="o">=</span>4g
</pre></div>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>配置主节点<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>登录 <code class="docutils literal notranslate"><span class="pre">node20</span></code>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker <span class="nb">exec</span> -it node20 bash
</pre></div>
</div>
<p>执行 <code class="docutils literal notranslate"><span class="pre">vim</span> <span class="pre">~/spark-3.0.0-preview2-bin-hadoop2.7/conf/spark-defaults.conf</span></code> 以编辑 <strong>spark-defaults.conf</strong> 文件。文件内容如下:</p>
<div class="highlight-txt notranslate"><div class="highlight"><pre><span></span>spark.executorEnv.PROJ_LIB         /home/arcterner/miniconda3/envs/arctern_env/share/proj
spark.executorEnv.GDAL_DATA        /home/arcterner/miniconda3/envs/arctern_env/share/gdal
spark.executor.memory              2g
spark.executor.cores               1
</pre></div>
</div>
<p>结合 <code class="docutils literal notranslate"><span class="pre">spark-env.sh</span></code> 和 <code class="docutils literal notranslate"><span class="pre">spark.defaults.conf</span></code> 可知，当前的 Spark 集群一共有 <code class="docutils literal notranslate"><span class="pre">2×3=6</span></code> 个 CPU，<code class="docutils literal notranslate"><span class="pre">4g×3=12g</span></code> 内存，并且每个 executor 使用 1 个<code class="docutils literal notranslate"><span class="pre">cpu</span></code>，2 G 内存，一共有 6 个 executor。</p>
<p>执行 <code class="docutils literal notranslate"><span class="pre">vim</span> <span class="pre">~/spark-3.0.0-preview2-bin-hadoop2.7/conf/slaves</span></code> 以编辑 <strong>slaves</strong> 文件。文件内容如下:</p>
<div class="highlight-txt notranslate"><div class="highlight"><pre><span></span>node20
node21
node22
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h2>设置免密登录<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><strong>注意：</strong> 后续所有操作均在 <code class="docutils literal notranslate"><span class="pre">node20</span></code> 上执行。</p>
</div></blockquote>
<p>退出 <code class="docutils literal notranslate"><span class="pre">node20</span> </code>的 root 账户，再以 <code class="docutils literal notranslate"><span class="pre">arcterner</span></code> 用户登录 <code class="docutils literal notranslate"><span class="pre">node20</span></code>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">exit</span>
docker <span class="nb">exec</span> -it -u arcterner node20 bash
</pre></div>
</div>
<p>设置 <code class="docutils literal notranslate"><span class="pre">master</span></code> 到 <code class="docutils literal notranslate"><span class="pre">woker</span></code> 的免密登录：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成 ssh-key，用于免密登录</span>
ssh-keygen -t rsa -P <span class="s1">&#39;&#39;</span> -f ~/.ssh/id_rsa

<span class="c1"># cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span>

<span class="c1"># 需要输入密码，密码为 arcterner</span>
ssh-copy-id node20
ssh-copy-id node21
ssh-copy-id node22
</pre></div>
</div>
</div>
<div class="section" id="id8">
<h2>启动 Spark 集群<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>启动 <code class="docutils literal notranslate"><span class="pre">master</span></code>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">$SPARK_HOME</span>/sbin/start-master.sh
</pre></div>
</div>
<p>关闭浏览器代理，在浏览器中输入 <code class="docutils literal notranslate"><span class="pre">http://172.18.0.20:8080/</span></code>，验证 <code class="docutils literal notranslate"><span class="pre">master</span></code> 是否正确启动：</p>
<p><img alt="查看 master" src="../../_images/standalone-cluster-start-master.png" /></p>
<p>启动 <code class="docutils literal notranslate"><span class="pre">slaves</span></code>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">$SPARK_HOME</span>/sbin/start-slaves.sh
</pre></div>
</div>
<p><img alt="启动 slaves" src="../../_images/standalone-cluster-start-slaves.png" /></p>
</div>
<div class="section" id="id9">
<h2>测试 Arctern<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>新建 <strong>gen.py</strong> 文件用于生成测试数据，内容如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="n">cnt</span><span class="o">=</span><span class="mi">1000000</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;idx,pos&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cnt</span><span class="p">):</span>
    <span class="n">lng</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">360</span> <span class="o">-</span> <span class="mi">180</span>
    <span class="n">lat</span> <span class="o">=</span> <span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">180</span> <span class="o">-</span> <span class="mi">90</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="s2">&quot;point(</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lng</span><span class="p">,</span><span class="n">lat</span><span class="p">),</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>生成测试数据，并将测试数据存入 <strong>/arcternas</strong>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python gen.py &gt; /arcternas/pos.csv
</pre></div>
</div>
<p>新建 <strong>st_transform_test.py</strong>，内容如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">from</span> <span class="nn">arctern_pyspark</span> <span class="kn">import</span> <span class="n">register_funcs</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span> \
        <span class="o">.</span><span class="n">builder</span> \
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;st_transform test&quot;</span><span class="p">)</span> \
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>

    <span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.sql.execution.arrow.pyspark.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
    <span class="n">register_funcs</span><span class="p">(</span><span class="n">spark</span><span class="p">)</span>

    <span class="n">df</span><span class="o">=</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;delimiter&quot;</span><span class="p">,</span><span class="s2">&quot;,&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="s2">&quot;idx long, pos string&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/arcternas/pos.csv&quot;</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
    <span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;pos&quot;</span><span class="p">)</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select idx,pos,st_transform(pos, &#39;epsg:4326&#39;, &#39;epsg:3857&#39;) from pos&quot;</span><span class="p">)</span>
    <span class="n">rst</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;/arcternas/st_transform/&quot;</span><span class="p">)</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
<p>向 Spark 提交 <strong>st_transform_test.py</strong>：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">$SPARK_HOME</span>/bin/spark-submit --master spark://node20:7077 st_transform_test.py
</pre></div>
</div>
<p>检查上述程序的运行结果：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ls -lh /arcternas/st_transform/
</pre></div>
</div>
<p>你也可以在浏览器中检查上述程序的运行情况：</p>
<p><img alt="运行情况" src="../../_images/standalone-cluster-submit-task.png" /></p>
</div>
<div class="section" id="id10">
<h2>参考文献<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>https://spark.apache.org/docs/latest/spark-standalone.html</p></li>
<li><p>https://www.programcreek.com/2018/11/install-spark-on-ubuntu-standalone-mode/</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, zilliz
      <span class="lastupdated">
        Last updated on Aug 04, 2020.
      </span>

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>